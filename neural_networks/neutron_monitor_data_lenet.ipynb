{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing necessary libraries\nimport os\n\nimport numpy as np\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n\nfrom sklearn.model_selection import KFold\n\nimport matplotlib.pyplot as plt\n\ntorch.manual_seed(42)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T19:44:49.818815Z","iopub.execute_input":"2022-12-15T19:44:49.819576Z","iopub.status.idle":"2022-12-15T19:44:49.827367Z","shell.execute_reply.started":"2022-12-15T19:44:49.819538Z","shell.execute_reply":"2022-12-15T19:44:49.826272Z"},"trusted":true},"execution_count":113,"outputs":[{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7fa58a398a10>"},"metadata":{}}]},{"cell_type":"code","source":"# Defining necessary parameters\nBATCH_SIZE = 1\nEPOCHS_COUNT = 15\nNUMBER_OF_SPLITS = 5","metadata":{"execution":{"iopub.status.busy":"2022-12-15T19:44:49.835206Z","iopub.execute_input":"2022-12-15T19:44:49.835471Z","iopub.status.idle":"2022-12-15T19:44:49.840313Z","shell.execute_reply.started":"2022-12-15T19:44:49.835446Z","shell.execute_reply":"2022-12-15T19:44:49.839260Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"# Defining a class for neutron monitor dataset\nclass NeutronMonitorDataset(Dataset):\n    def __init__(self):\n        super().__init__()\n        self._wavelets_files, self._labels = NeutronMonitorDataset._get_neutron_monitor_data_files()\n        self._length = len(self._wavelets_files)\n    \n    @staticmethod\n    def _get_neutron_monitor_data_files():\n        wavelets_files, labels = [], []\n        data_dirs_paths = [\n            \"../input/sopo-neutron-monitor-data/calm_days\",\n            \"../input/sopo-neutron-monitor-data/weak_storms\",\n            \"../input/sopo-neutron-monitor-data/strong_storms\"\n        ]     \n        for index, dir_path in enumerate(data_dirs_paths):\n            wavelets_array, labels_array = NeutronMonitorDataset._get_data_files_from_directory(dir_path, index)\n            wavelets_files.extend(wavelets_array)\n            labels.extend(labels_array)\n        return wavelets_files, labels\n    \n    @staticmethod\n    def _get_data_files_from_directory(dir_path, label):\n        wavelets_files_array = []\n        for _, _, files in os.walk(dir_path):\n            for file in files:\n                if file != \".gitkeep\":\n                    file_path = os.path.join(dir_path, file)\n                    wavelets_files_array.append(file_path)\n        labels_array = [label for _ in range(len(wavelets_files_array))]\n        return wavelets_files_array, labels_array\n    \n    def __len__(self):\n        return self._length\n    \n    def __getitem__(self, index):\n        sample_wavelet_file = self._wavelets_files[index]\n        sample_wavelet_image = torch.tensor(\n            np.loadtxt(sample_wavelet_file, dtype=np.float64, delimiter=','),\n            dtype=torch.float32\n        )\n        sample_label = self._labels[index]\n        return sample_wavelet_image, sample_label","metadata":{"execution":{"iopub.status.busy":"2022-12-15T19:44:49.849311Z","iopub.execute_input":"2022-12-15T19:44:49.850203Z","iopub.status.idle":"2022-12-15T19:44:49.864832Z","shell.execute_reply.started":"2022-12-15T19:44:49.850170Z","shell.execute_reply":"2022-12-15T19:44:49.863684Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"# defining modified LeNet model for neutron monitor data\nclass NeutronMonitorDataLeNet(nn.Module):\n    def __init__(self):\n        super(NeutronMonitorDataLeNet, self).__init__()\n        self.feature_extractor = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3),\n            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3),\n            nn.Flatten(0)\n        )\n        self.classifier = nn.Sequential(\n            nn.Linear(in_features=63600, out_features=120),\n            nn.ReLU(),\n            nn.Linear(in_features=120, out_features=84),\n            nn.ReLU(),\n            nn.Linear(in_features=84, out_features=3)\n        )\n        \n    def forward(self, x):\n        x = self.feature_extractor(x)\n        # print(x.shape)\n        logits = self.classifier(x)\n        probs = F.softmax(logits, dim=0)\n        return logits, probs","metadata":{"execution":{"iopub.status.busy":"2022-12-15T19:44:49.867195Z","iopub.execute_input":"2022-12-15T19:44:49.867540Z","iopub.status.idle":"2022-12-15T19:44:49.880896Z","shell.execute_reply.started":"2022-12-15T19:44:49.867506Z","shell.execute_reply":"2022-12-15T19:44:49.879725Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"# Defining train function\ndef train(train_loader, model, criterion, optimizer, device):\n    model.train()\n    running_loss = 0\n    for X, y_true in train_loader:\n        optimizer.zero_grad()\n        X, y_true = X.to(device), y_true.to(device)\n        y_got, _ = model(X) \n        loss = criterion(y_got, y_true[0]) \n        running_loss += loss.item() * X.size(0)\n        loss.backward()\n        optimizer.step()\n    epoch_loss = running_loss / len(train_loader.dataset)\n    return model, optimizer, epoch_loss","metadata":{"execution":{"iopub.status.busy":"2022-12-15T19:44:49.882477Z","iopub.execute_input":"2022-12-15T19:44:49.882833Z","iopub.status.idle":"2022-12-15T19:44:49.894884Z","shell.execute_reply.started":"2022-12-15T19:44:49.882799Z","shell.execute_reply":"2022-12-15T19:44:49.894016Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"# Defining validation function\ndef validate(valid_loader, model, criterion, device):\n    model.eval()\n    running_loss = 0\n    for X, y_true in valid_loader:\n        X, y_true = X.to(device), y_true.to(device)\n        y_got, _ = model(X) \n        loss = criterion(y_got, y_true[0]) \n        running_loss += loss.item() * X.size(0)\n    epoch_loss = running_loss / len(valid_loader.dataset)\n    return model, epoch_loss","metadata":{"execution":{"iopub.status.busy":"2022-12-15T19:44:49.897260Z","iopub.execute_input":"2022-12-15T19:44:49.897769Z","iopub.status.idle":"2022-12-15T19:44:49.905172Z","shell.execute_reply.started":"2022-12-15T19:44:49.897736Z","shell.execute_reply":"2022-12-15T19:44:49.904118Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"# Defining helper functions\ndef get_accuracy(model, data_loader, device):\n    correct_pred = 0 \n    n = 0\n    with torch.no_grad():\n        model.eval()\n        for X, y_true in data_loader:\n            X, y_true = X.type(torch.float32).to(device), y_true.to(device)\n            _, y_prob = model(X)\n            _, predicted_labels = torch.max(y_prob, 0)\n            n += y_true.size(0)\n            correct_pred += (predicted_labels == y_true).sum()\n    return correct_pred.float() / n\n\n\ndef plot_losses(train_losses, valid_losses):\n    plt.style.use('seaborn')\n    train_losses = np.array(train_losses) \n    valid_losses = np.array(valid_losses)\n    fig, ax = plt.subplots(figsize = (8, 4.5))\n    ax.plot(train_losses, color='blue', label='Training loss') \n    ax.plot(valid_losses, color='red', label='Validation loss')\n    ax.set(title=\"Loss over epochs\", xlabel='Epoch', ylabel='Loss')\n    ax.legend()\n    fig.show()\n    plt.style.use('default')","metadata":{"execution":{"iopub.status.busy":"2022-12-15T19:44:49.906789Z","iopub.execute_input":"2022-12-15T19:44:49.907131Z","iopub.status.idle":"2022-12-15T19:44:49.917309Z","shell.execute_reply.started":"2022-12-15T19:44:49.907098Z","shell.execute_reply":"2022-12-15T19:44:49.916431Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"# Defining training loop function with KFold\ndef training_kfold_loop(model, criterion, optimizer, train_valid_dataset, splits, epochs, device):\n    history = {\"train_losses\": [], \"valid_losses\": [], \"train_accuracy\": [], \"valid_accuracy\": []}\n    for fold, (train_indices, valid_indices) in enumerate(splits.split(np.arange(len(train_valid_dataset)))):\n        print(f'Fold {fold + 1}')\n        train_sampler = SubsetRandomSampler(train_indices)\n        valid_sampler = SubsetRandomSampler(valid_indices)\n        train_loader = DataLoader(train_valid_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n        valid_loader = DataLoader(train_valid_dataset, batch_size=BATCH_SIZE, sampler=valid_sampler)\n        for epoch in range(0, epochs):\n            # training\n            model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n            history[\"train_losses\"].append(train_loss)\n            # validation\n            with torch.no_grad():\n                model, valid_loss = validate(valid_loader, model, criterion, device)\n                history[\"valid_losses\"].append(valid_loss)\n            train_accuracy = get_accuracy(model, train_loader, device)\n            train_accuracy = train_accuracy.data.cpu().numpy() * 100\n            valid_accuracy = get_accuracy(model, valid_loader, device)\n            valid_accuracy = valid_accuracy.data.cpu().numpy() * 100\n            history[\"train_accuracy\"].append(train_accuracy)\n            history[\"valid_accuracy\"].append(valid_accuracy)\n            print(f'Epoch: {fold + 1}.{epoch + 1}\\tTrain loss: {train_loss:.4f}\\tValid loss: {valid_loss:.4f}\\t'\n                  f'Train accuracy: {train_accuracy:.2f}\\tValid accuracy: {valid_accuracy:.2f}')\n    print(f\"Average TL: {np.mean(history['train_losses']):.4f}\\tAverage VL: {np.mean(history['valid_losses']):.4f}\\t\"\n          f\"Average TA: {np.mean(history['train_accuracy']):.2f}\\tAverage VA: {np.mean(history['valid_accuracy']):.2f}\")\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-15T19:44:49.952485Z","iopub.execute_input":"2022-12-15T19:44:49.952814Z","iopub.status.idle":"2022-12-15T19:44:49.965095Z","shell.execute_reply.started":"2022-12-15T19:44:49.952788Z","shell.execute_reply":"2022-12-15T19:44:49.963717Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"# Defining training loop function without KFold\ndef training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device):\n    for epoch in range(0, epochs):\n        # training\n        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n        # validation\n        with torch.no_grad():\n            model, valid_loss = validate(valid_loader, model, criterion, device)\n        train_accuracy = get_accuracy(model, train_loader, device)\n        train_accuracy = train_accuracy.data.cpu().numpy() * 100\n        valid_accuracy = get_accuracy(model, valid_loader, device)\n        valid_accuracy = valid_accuracy.data.cpu().numpy() * 100\n        print(f'Epoch: {epoch + 1}\\tTrain loss: {train_loss:.4f}\\tValid loss: {valid_loss:.4f}\\t'\n              f'Train accuracy: {train_accuracy:.2f}\\tValid accuracy: {valid_accuracy:.2f}')\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:20:37.892042Z","iopub.execute_input":"2022-12-15T21:20:37.892398Z","iopub.status.idle":"2022-12-15T21:20:37.900970Z","shell.execute_reply.started":"2022-12-15T21:20:37.892366Z","shell.execute_reply":"2022-12-15T21:20:37.899899Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"# Defining the device which will be used to train the model\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:11:17.899069Z","iopub.execute_input":"2022-12-15T21:11:17.899430Z","iopub.status.idle":"2022-12-15T21:11:17.905542Z","shell.execute_reply.started":"2022-12-15T21:11:17.899398Z","shell.execute_reply":"2022-12-15T21:11:17.904433Z"},"trusted":true},"execution_count":130,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# Creating datasets and KFold\nfull_dataset = NeutronMonitorDataset()\ntrain_valid_dataset, test_dataset = random_split(full_dataset, [85, 10], generator=torch.Generator().manual_seed(42))\nsplits = KFold(n_splits=NUMBER_OF_SPLITS, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T19:44:49.980314Z","iopub.execute_input":"2022-12-15T19:44:49.981520Z","iopub.status.idle":"2022-12-15T19:44:49.994511Z","shell.execute_reply.started":"2022-12-15T19:44:49.981485Z","shell.execute_reply":"2022-12-15T19:44:49.993721Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"# Training model using KFold\nmodel = NeutronMonitorDataLeNet().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters())\nmodel = training_kfold_loop(\n    model, criterion, optimizer, train_valid_dataset, splits, EPOCHS_COUNT, device\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T19:44:50.069699Z","iopub.execute_input":"2022-12-15T19:44:50.070156Z","iopub.status.idle":"2022-12-15T20:29:54.302316Z","shell.execute_reply.started":"2022-12-15T19:44:50.070121Z","shell.execute_reply":"2022-12-15T20:29:54.300295Z"},"trusted":true},"execution_count":124,"outputs":[{"name":"stdout","text":"Fold 1\nEpoch: 1.1\tTrain loss: 8.6579\tValid loss: 0.2207\tTrain accuracy: 51.47\tValid accuracy: 64.71\nEpoch: 1.2\tTrain loss: 0.9745\tValid loss: 0.1873\tTrain accuracy: 88.24\tValid accuracy: 47.06\nEpoch: 1.3\tTrain loss: 0.7298\tValid loss: 0.4780\tTrain accuracy: 58.82\tValid accuracy: 41.18\nEpoch: 1.4\tTrain loss: 0.3767\tValid loss: 0.1565\tTrain accuracy: 94.12\tValid accuracy: 64.71\nEpoch: 1.5\tTrain loss: 0.1976\tValid loss: 0.2096\tTrain accuracy: 100.00\tValid accuracy: 58.82\nEpoch: 1.6\tTrain loss: 0.0235\tValid loss: 0.2556\tTrain accuracy: 100.00\tValid accuracy: 52.94\nEpoch: 1.7\tTrain loss: 0.0034\tValid loss: 0.2572\tTrain accuracy: 100.00\tValid accuracy: 58.82\nEpoch: 1.8\tTrain loss: 0.0018\tValid loss: 0.2693\tTrain accuracy: 100.00\tValid accuracy: 64.71\nEpoch: 1.9\tTrain loss: 0.0011\tValid loss: 0.2785\tTrain accuracy: 100.00\tValid accuracy: 64.71\nEpoch: 1.10\tTrain loss: 0.0008\tValid loss: 0.2826\tTrain accuracy: 100.00\tValid accuracy: 64.71\nEpoch: 1.11\tTrain loss: 0.0006\tValid loss: 0.2890\tTrain accuracy: 100.00\tValid accuracy: 64.71\nEpoch: 1.12\tTrain loss: 0.0004\tValid loss: 0.2936\tTrain accuracy: 100.00\tValid accuracy: 64.71\nEpoch: 1.13\tTrain loss: 0.0004\tValid loss: 0.2974\tTrain accuracy: 100.00\tValid accuracy: 64.71\nEpoch: 1.14\tTrain loss: 0.0003\tValid loss: 0.2979\tTrain accuracy: 100.00\tValid accuracy: 64.71\nEpoch: 1.15\tTrain loss: 0.0002\tValid loss: 0.3025\tTrain accuracy: 100.00\tValid accuracy: 64.71\nFold 2\nEpoch: 2.1\tTrain loss: 0.8538\tValid loss: 0.0611\tTrain accuracy: 98.53\tValid accuracy: 100.00\nEpoch: 2.2\tTrain loss: 0.1907\tValid loss: 0.0727\tTrain accuracy: 98.53\tValid accuracy: 88.24\nEpoch: 2.3\tTrain loss: 0.0311\tValid loss: 0.0218\tTrain accuracy: 100.00\tValid accuracy: 94.12\nEpoch: 2.4\tTrain loss: 0.0037\tValid loss: 0.0247\tTrain accuracy: 100.00\tValid accuracy: 94.12\nEpoch: 2.5\tTrain loss: 0.0017\tValid loss: 0.0256\tTrain accuracy: 100.00\tValid accuracy: 94.12\nEpoch: 2.6\tTrain loss: 0.0011\tValid loss: 0.0265\tTrain accuracy: 100.00\tValid accuracy: 94.12\nEpoch: 2.7\tTrain loss: 0.0008\tValid loss: 0.0284\tTrain accuracy: 100.00\tValid accuracy: 94.12\nEpoch: 2.8\tTrain loss: 0.0006\tValid loss: 0.0298\tTrain accuracy: 100.00\tValid accuracy: 94.12\nEpoch: 2.9\tTrain loss: 0.0005\tValid loss: 0.0309\tTrain accuracy: 100.00\tValid accuracy: 94.12\nEpoch: 2.10\tTrain loss: 0.0004\tValid loss: 0.0319\tTrain accuracy: 100.00\tValid accuracy: 94.12\nEpoch: 2.11\tTrain loss: 0.0003\tValid loss: 0.0333\tTrain accuracy: 100.00\tValid accuracy: 94.12\nEpoch: 2.12\tTrain loss: 0.0003\tValid loss: 0.0346\tTrain accuracy: 100.00\tValid accuracy: 94.12\nEpoch: 2.13\tTrain loss: 0.0002\tValid loss: 0.0350\tTrain accuracy: 100.00\tValid accuracy: 94.12\nEpoch: 2.14\tTrain loss: 0.0002\tValid loss: 0.0365\tTrain accuracy: 100.00\tValid accuracy: 94.12\nEpoch: 2.15\tTrain loss: 0.0002\tValid loss: 0.0380\tTrain accuracy: 100.00\tValid accuracy: 94.12\nFold 3\nEpoch: 3.1\tTrain loss: 0.2559\tValid loss: 0.0031\tTrain accuracy: 97.06\tValid accuracy: 100.00\nEpoch: 3.2\tTrain loss: 0.0200\tValid loss: 0.0014\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 3.3\tTrain loss: 0.0025\tValid loss: 0.0007\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 3.4\tTrain loss: 0.0005\tValid loss: 0.0005\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 3.5\tTrain loss: 0.0002\tValid loss: 0.0006\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 3.6\tTrain loss: 0.0001\tValid loss: 0.0007\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 3.7\tTrain loss: 0.0001\tValid loss: 0.0007\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 3.8\tTrain loss: 0.0001\tValid loss: 0.0007\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 3.9\tTrain loss: 0.0001\tValid loss: 0.0006\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 3.10\tTrain loss: 0.0001\tValid loss: 0.0007\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 3.11\tTrain loss: 0.0000\tValid loss: 0.0006\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 3.12\tTrain loss: 0.0000\tValid loss: 0.0006\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 3.13\tTrain loss: 0.0000\tValid loss: 0.0006\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 3.14\tTrain loss: 0.0000\tValid loss: 0.0006\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 3.15\tTrain loss: 0.0000\tValid loss: 0.0006\tTrain accuracy: 100.00\tValid accuracy: 100.00\nFold 4\nEpoch: 4.1\tTrain loss: 0.0003\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 4.2\tTrain loss: 0.0001\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 4.3\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 4.4\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 4.5\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 4.6\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 4.7\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 4.8\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 4.9\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 4.10\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 4.11\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 4.12\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 4.13\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 4.14\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 4.15\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nFold 5\nEpoch: 5.1\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 5.2\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 5.3\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 5.4\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 5.5\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 5.6\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 5.7\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 5.8\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 5.9\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 5.10\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 5.11\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 5.12\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 5.13\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 5.14\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nEpoch: 5.15\tTrain loss: 0.0000\tValid loss: 0.0000\tTrain accuracy: 100.00\tValid accuracy: 100.00\nAverage TL: 0.1645\tAverage VL: 0.0616\tAverage TA: 98.49\tAverage VA: 90.90\n","output_type":"stream"}]},{"cell_type":"code","source":"# Training model without KFold\ntrain_dataset, valid_dataset = random_split(train_valid_dataset, [66, 19], generator=torch.Generator().manual_seed(42))\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\nvalid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n\nmodel = NeutronMonitorDataLeNet().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters())\nmodel = training_loop(\n    model, criterion, optimizer, train_loader, valid_loader, EPOCHS_COUNT, device\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:20:46.567916Z","iopub.execute_input":"2022-12-15T21:20:46.568325Z","iopub.status.idle":"2022-12-15T21:30:05.318069Z","shell.execute_reply.started":"2022-12-15T21:20:46.568292Z","shell.execute_reply":"2022-12-15T21:30:05.316933Z"},"trusted":true},"execution_count":135,"outputs":[{"name":"stdout","text":"Epoch: 1\tTrain loss: 6.4520\tValid loss: 2.1488\tTrain accuracy: 53.03\tValid accuracy: 31.58\nEpoch: 2\tTrain loss: 1.0512\tValid loss: 1.0645\tTrain accuracy: 71.21\tValid accuracy: 52.63\nEpoch: 3\tTrain loss: 0.8455\tValid loss: 0.9469\tTrain accuracy: 84.85\tValid accuracy: 52.63\nEpoch: 4\tTrain loss: 0.6145\tValid loss: 1.0036\tTrain accuracy: 84.85\tValid accuracy: 47.37\nEpoch: 5\tTrain loss: 0.4124\tValid loss: 1.1278\tTrain accuracy: 98.48\tValid accuracy: 47.37\nEpoch: 6\tTrain loss: 0.2840\tValid loss: 1.2446\tTrain accuracy: 95.45\tValid accuracy: 47.37\nEpoch: 7\tTrain loss: 0.1746\tValid loss: 2.0533\tTrain accuracy: 86.36\tValid accuracy: 31.58\nEpoch: 8\tTrain loss: 0.1241\tValid loss: 2.3540\tTrain accuracy: 98.48\tValid accuracy: 31.58\nEpoch: 9\tTrain loss: 0.0127\tValid loss: 2.3544\tTrain accuracy: 100.00\tValid accuracy: 42.11\nEpoch: 10\tTrain loss: 0.0047\tValid loss: 3.1452\tTrain accuracy: 100.00\tValid accuracy: 47.37\nEpoch: 11\tTrain loss: 0.0029\tValid loss: 2.2175\tTrain accuracy: 100.00\tValid accuracy: 47.37\nEpoch: 12\tTrain loss: 0.0007\tValid loss: 2.3681\tTrain accuracy: 100.00\tValid accuracy: 47.37\nEpoch: 13\tTrain loss: 0.0004\tValid loss: 2.6031\tTrain accuracy: 100.00\tValid accuracy: 47.37\nEpoch: 14\tTrain loss: 0.0003\tValid loss: 2.7383\tTrain accuracy: 100.00\tValid accuracy: 47.37\nEpoch: 15\tTrain loss: 0.0002\tValid loss: 2.8153\tTrain accuracy: 100.00\tValid accuracy: 47.37\n","output_type":"stream"}]},{"cell_type":"code","source":"# Testing model\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\ntest_accuracy = get_accuracy(model, test_loader, device)\nprint(f\"{100 * test_accuracy:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:30:50.832470Z","iopub.execute_input":"2022-12-15T21:30:50.832891Z","iopub.status.idle":"2022-12-15T21:30:52.974664Z","shell.execute_reply.started":"2022-12-15T21:30:50.832856Z","shell.execute_reply":"2022-12-15T21:30:52.973572Z"},"trusted":true},"execution_count":136,"outputs":[{"name":"stdout","text":"60.00\n","output_type":"stream"}]}]}