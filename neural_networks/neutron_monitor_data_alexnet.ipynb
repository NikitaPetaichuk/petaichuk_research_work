{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c68a010",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T16:50:02.033967Z",
     "iopub.status.busy": "2022-12-18T16:50:02.033450Z",
     "iopub.status.idle": "2022-12-18T16:50:04.029614Z",
     "shell.execute_reply": "2022-12-18T16:50:04.028413Z"
    },
    "papermill": {
     "duration": 2.00517,
     "end_time": "2022-12-18T16:50:04.032266",
     "exception": false,
     "start_time": "2022-12-18T16:50:02.027096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3a34776970>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2041c122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T16:50:04.041863Z",
     "iopub.status.busy": "2022-12-18T16:50:04.041307Z",
     "iopub.status.idle": "2022-12-18T16:50:04.046427Z",
     "shell.execute_reply": "2022-12-18T16:50:04.045368Z"
    },
    "papermill": {
     "duration": 0.012265,
     "end_time": "2022-12-18T16:50:04.048723",
     "exception": false,
     "start_time": "2022-12-18T16:50:04.036458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining necessary parameters\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS_COUNT = 15\n",
    "NUMBER_OF_SPLITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57139022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T16:50:04.058017Z",
     "iopub.status.busy": "2022-12-18T16:50:04.057117Z",
     "iopub.status.idle": "2022-12-18T16:50:04.067232Z",
     "shell.execute_reply": "2022-12-18T16:50:04.066431Z"
    },
    "papermill": {
     "duration": 0.016635,
     "end_time": "2022-12-18T16:50:04.069207",
     "exception": false,
     "start_time": "2022-12-18T16:50:04.052572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining a class for neutron monitor dataset\n",
    "class NeutronMonitorDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._wavelets_files, self._labels = NeutronMonitorDataset._get_neutron_monitor_data_files()\n",
    "        self._length = len(self._wavelets_files)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_neutron_monitor_data_files():\n",
    "        wavelets_files, labels = [], []\n",
    "        data_dirs_paths = [\n",
    "            \"../input/sopo-neutron-monitor-data/calm_days\",\n",
    "            \"../input/sopo-neutron-monitor-data/weak_storms\",\n",
    "            \"../input/sopo-neutron-monitor-data/strong_storms\"\n",
    "        ]     \n",
    "        for index, dir_path in enumerate(data_dirs_paths):\n",
    "            wavelets_array, labels_array = NeutronMonitorDataset._get_data_files_from_directory(dir_path, index)\n",
    "            wavelets_files.extend(wavelets_array)\n",
    "            labels.extend(labels_array)\n",
    "        return wavelets_files, labels\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_data_files_from_directory(dir_path, label):\n",
    "        wavelets_files_array = []\n",
    "        for _, _, files in os.walk(dir_path):\n",
    "            for file in files:\n",
    "                if file != \".gitkeep\":\n",
    "                    file_path = os.path.join(dir_path, file)\n",
    "                    wavelets_files_array.append(file_path)\n",
    "        labels_array = [label for _ in range(len(wavelets_files_array))]\n",
    "        return wavelets_files_array, labels_array\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample_wavelet_file = self._wavelets_files[index]\n",
    "        sample_wavelet_image = torch.tensor(\n",
    "            np.loadtxt(sample_wavelet_file, dtype=np.float64, delimiter=','),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        sample_label = self._labels[index]\n",
    "        return sample_wavelet_image, sample_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "671f1e57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T16:50:04.077996Z",
     "iopub.status.busy": "2022-12-18T16:50:04.077062Z",
     "iopub.status.idle": "2022-12-18T16:50:04.087370Z",
     "shell.execute_reply": "2022-12-18T16:50:04.086623Z"
    },
    "papermill": {
     "duration": 0.01675,
     "end_time": "2022-12-18T16:50:04.089450",
     "exception": false,
     "start_time": "2022-12-18T16:50:04.072700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining modified LeNet model for neutron monitor data\n",
    "class NeutronMonitorDataLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeutronMonitorDataLeNet, self).__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Flatten(0)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=1075200, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=4096, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=4096, out_features=3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        # print(x.shape)\n",
    "        logits = self.classifier(x)\n",
    "        probs = F.softmax(logits, dim=0)\n",
    "        return logits, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db5d8ce0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T16:50:04.098001Z",
     "iopub.status.busy": "2022-12-18T16:50:04.097689Z",
     "iopub.status.idle": "2022-12-18T16:50:04.103743Z",
     "shell.execute_reply": "2022-12-18T16:50:04.102797Z"
    },
    "papermill": {
     "duration": 0.012621,
     "end_time": "2022-12-18T16:50:04.105689",
     "exception": false,
     "start_time": "2022-12-18T16:50:04.093068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining train function\n",
    "def train(train_loader, model, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for X, y_true in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        X, y_true = X.to(device), y_true.to(device)\n",
    "        y_got, _ = model(X) \n",
    "        loss = criterion(y_got, y_true[0]) \n",
    "        running_loss += loss.item() * X.size(0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return model, optimizer, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a51f883f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T16:50:04.114238Z",
     "iopub.status.busy": "2022-12-18T16:50:04.113443Z",
     "iopub.status.idle": "2022-12-18T16:50:04.119505Z",
     "shell.execute_reply": "2022-12-18T16:50:04.118694Z"
    },
    "papermill": {
     "duration": 0.01223,
     "end_time": "2022-12-18T16:50:04.121450",
     "exception": false,
     "start_time": "2022-12-18T16:50:04.109220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining validation function\n",
    "def validate(valid_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    for X, y_true in valid_loader:\n",
    "        X, y_true = X.to(device), y_true.to(device)\n",
    "        y_got, _ = model(X) \n",
    "        loss = criterion(y_got, y_true[0]) \n",
    "        running_loss += loss.item() * X.size(0)\n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "    return model, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df6ca235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T16:50:04.129530Z",
     "iopub.status.busy": "2022-12-18T16:50:04.129245Z",
     "iopub.status.idle": "2022-12-18T16:50:04.137015Z",
     "shell.execute_reply": "2022-12-18T16:50:04.136057Z"
    },
    "papermill": {
     "duration": 0.014026,
     "end_time": "2022-12-18T16:50:04.138943",
     "exception": false,
     "start_time": "2022-12-18T16:50:04.124917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining helper functions\n",
    "def get_accuracy(model, data_loader, device):\n",
    "    correct_pred = 0 \n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X, y_true in data_loader:\n",
    "            X, y_true = X.type(torch.float32).to(device), y_true.to(device)\n",
    "            _, y_prob = model(X)\n",
    "            _, predicted_labels = torch.max(y_prob, 0)\n",
    "            n += y_true.size(0)\n",
    "            correct_pred += (predicted_labels == y_true).sum()\n",
    "    return correct_pred.float() / n\n",
    "\n",
    "\n",
    "def plot_losses(train_losses, valid_losses):\n",
    "    plt.style.use('seaborn')\n",
    "    train_losses = np.array(train_losses) \n",
    "    valid_losses = np.array(valid_losses)\n",
    "    fig, ax = plt.subplots(figsize = (8, 4.5))\n",
    "    ax.plot(train_losses, color='blue', label='Training loss') \n",
    "    ax.plot(valid_losses, color='red', label='Validation loss')\n",
    "    ax.set(title=\"Loss over epochs\", xlabel='Epoch', ylabel='Loss')\n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "    plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5feec73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T16:50:04.147554Z",
     "iopub.status.busy": "2022-12-18T16:50:04.147253Z",
     "iopub.status.idle": "2022-12-18T16:50:04.156240Z",
     "shell.execute_reply": "2022-12-18T16:50:04.155387Z"
    },
    "papermill": {
     "duration": 0.015668,
     "end_time": "2022-12-18T16:50:04.158211",
     "exception": false,
     "start_time": "2022-12-18T16:50:04.142543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining training loop function with KFold\n",
    "def training_kfold_loop(model, criterion, optimizer, train_valid_dataset, splits, epochs, device):\n",
    "    history = {\"train_losses\": [], \"valid_losses\": [], \"train_accuracy\": [], \"valid_accuracy\": []}\n",
    "    for fold, (train_indices, valid_indices) in enumerate(splits.split(np.arange(len(train_valid_dataset)))):\n",
    "        print(f'Fold {fold + 1}')\n",
    "        train_sampler = SubsetRandomSampler(train_indices)\n",
    "        valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "        train_loader = DataLoader(train_valid_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "        valid_loader = DataLoader(train_valid_dataset, batch_size=BATCH_SIZE, sampler=valid_sampler)\n",
    "        for epoch in range(0, epochs):\n",
    "            # training\n",
    "            model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n",
    "            history[\"train_losses\"].append(train_loss)\n",
    "            # validation\n",
    "            with torch.no_grad():\n",
    "                model, valid_loss = validate(valid_loader, model, criterion, device)\n",
    "                history[\"valid_losses\"].append(valid_loss)\n",
    "            train_accuracy = get_accuracy(model, train_loader, device)\n",
    "            train_accuracy = train_accuracy.data.cpu().numpy() * 100\n",
    "            valid_accuracy = get_accuracy(model, valid_loader, device)\n",
    "            valid_accuracy = valid_accuracy.data.cpu().numpy() * 100\n",
    "            history[\"train_accuracy\"].append(train_accuracy)\n",
    "            history[\"valid_accuracy\"].append(valid_accuracy)\n",
    "            print(f'Epoch: {fold + 1}.{epoch + 1}\\tTrain loss: {train_loss:.4f}\\tValid loss: {valid_loss:.4f}\\t'\n",
    "                  f'Train accuracy: {train_accuracy:.2f}\\tValid accuracy: {valid_accuracy:.2f}')\n",
    "    print(f\"Average TL: {np.mean(history['train_losses']):.4f}\\tAverage VL: {np.mean(history['valid_losses']):.4f}\\t\"\n",
    "          f\"Average TA: {np.mean(history['train_accuracy']):.2f}\\tAverage VA: {np.mean(history['valid_accuracy']):.2f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2144975c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T16:50:04.167495Z",
     "iopub.status.busy": "2022-12-18T16:50:04.166101Z",
     "iopub.status.idle": "2022-12-18T16:50:04.173022Z",
     "shell.execute_reply": "2022-12-18T16:50:04.172179Z"
    },
    "papermill": {
     "duration": 0.013311,
     "end_time": "2022-12-18T16:50:04.174986",
     "exception": false,
     "start_time": "2022-12-18T16:50:04.161675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining training loop function without KFold\n",
    "def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device):\n",
    "    for epoch in range(0, epochs):\n",
    "        # training\n",
    "        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n",
    "        # validation\n",
    "        with torch.no_grad():\n",
    "            model, valid_loss = validate(valid_loader, model, criterion, device)\n",
    "        train_accuracy = get_accuracy(model, train_loader, device)\n",
    "        train_accuracy = train_accuracy.data.cpu().numpy() * 100\n",
    "        valid_accuracy = get_accuracy(model, valid_loader, device)\n",
    "        valid_accuracy = valid_accuracy.data.cpu().numpy() * 100\n",
    "        print(f'Epoch: {epoch + 1}\\tTrain loss: {train_loss:.4f}\\tValid loss: {valid_loss:.4f}\\t'\n",
    "              f'Train accuracy: {train_accuracy:.2f}\\tValid accuracy: {valid_accuracy:.2f}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52750148",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T16:50:04.183592Z",
     "iopub.status.busy": "2022-12-18T16:50:04.182991Z",
     "iopub.status.idle": "2022-12-18T16:50:04.236594Z",
     "shell.execute_reply": "2022-12-18T16:50:04.235490Z"
    },
    "papermill": {
     "duration": 0.060212,
     "end_time": "2022-12-18T16:50:04.238875",
     "exception": false,
     "start_time": "2022-12-18T16:50:04.178663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Defining the device which will be used to train the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c08c3c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T16:50:04.247776Z",
     "iopub.status.busy": "2022-12-18T16:50:04.246990Z",
     "iopub.status.idle": "2022-12-18T16:50:04.290754Z",
     "shell.execute_reply": "2022-12-18T16:50:04.289897Z"
    },
    "papermill": {
     "duration": 0.050355,
     "end_time": "2022-12-18T16:50:04.292968",
     "exception": false,
     "start_time": "2022-12-18T16:50:04.242613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating datasets and KFold\n",
    "full_dataset = NeutronMonitorDataset()\n",
    "train_valid_dataset, test_dataset = random_split(full_dataset, [85, 10], generator=torch.Generator().manual_seed(42))\n",
    "splits = KFold(n_splits=NUMBER_OF_SPLITS, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bb46d8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T16:50:04.302590Z",
     "iopub.status.busy": "2022-12-18T16:50:04.301030Z"
    },
    "papermill": {
     "duration": 34.783935,
     "end_time": "2022-12-18T16:50:39.080412",
     "exception": false,
     "start_time": "2022-12-18T16:50:04.296477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training model using KFold\n",
    "model = NeutronMonitorDataLeNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "model = training_kfold_loop(\n",
    "    model, criterion, optimizer, train_valid_dataset, splits, EPOCHS_COUNT, device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24be4940",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T16:15:50.180523Z",
     "iopub.status.busy": "2022-12-18T16:15:50.180040Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training model without KFold\n",
    "train_dataset, valid_dataset = random_split(train_valid_dataset, [66, 19], generator=torch.Generator().manual_seed(42))\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = NeutronMonitorDataLeNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "model = training_loop(\n",
    "    model, criterion, optimizer, train_loader, valid_loader, EPOCHS_COUNT, device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c4d92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T16:03:21.829967Z",
     "iopub.status.busy": "2022-12-18T16:03:21.829593Z",
     "iopub.status.idle": "2022-12-18T16:03:23.910081Z",
     "shell.execute_reply": "2022-12-18T16:03:23.909038Z",
     "shell.execute_reply.started": "2022-12-18T16:03:21.829935Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing model\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "test_accuracy = get_accuracy(model, test_loader, device)\n",
    "print(f\"{100 * test_accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 44.484914,
   "end_time": "2022-12-18T16:50:39.106867",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-18T16:49:54.621953",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
